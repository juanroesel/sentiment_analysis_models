{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "opponent-israeli",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Movie Reviews\n",
    "\n",
    "This exercise was developed as part of the Supervised Learning course (DSCI 571) taken at the Master of Data Science & Computational Linguistics program offered at the University of British Columbia.\n",
    "\n",
    "The goal of this exercise was to test different classifiers to carry out sentiment analysis in the [IMDB Movie Reviews dataset](https://www.kaggle.com/utathya/imdb-review-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "personal-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "# python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# train test split and cross validation\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "# sklearn objects\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-monitor",
   "metadata": {},
   "source": [
    "### Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "whole-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df = pd.read_csv(\"data/imdb_master.csv\", encoding=\"ISO-8859-1\", index_col=\"Unnamed: 0\")\n",
    "imdb_df = imdb_df.query('label == \"neg\" | label == \"pos\"')\n",
    "train_df = imdb_df.query('type == \"train\"')\n",
    "test_df = imdb_df.query('type == \"test\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thorough-recording",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inside-briefing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "silent-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_train, X_test, y_train, y_test\n",
    "X_train, y_train = train_df.drop(columns = [\"label\"]), train_df[\"label\"]\n",
    "X_test, y_test = test_df.drop(columns = [\"label\"]), test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-superior",
   "metadata": {},
   "source": [
    "### Initial EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nasty-senate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    0.5\n",
       "pos    0.5\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class balance\n",
    "y_train.value_counts(\"neg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-infrared",
   "metadata": {},
   "source": [
    "> Classes are equally distributed (50% / 50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quality-traveler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25000 entries, 25000 to 49999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   type    25000 non-null  object\n",
      " 1   review  25000 non-null  object\n",
      " 2   file    25000 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 781.2+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-cyprus",
   "metadata": {},
   "source": [
    "> There are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-detector",
   "metadata": {},
   "source": [
    "### Model building and hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fresh-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit: This function was adapted from Varada Kolhatkar (MDS instructor)\n",
    "def store_cross_val_results(model_name, scores, results_dict):\n",
    "    \"\"\"\n",
    "    Stores mean scores from cross_validate in results_dict for\n",
    "    the given model model_name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name :\n",
    "        scikit-learn classification model\n",
    "    scores : dict\n",
    "        object return by `cross_validate`\n",
    "    results_dict: dict\n",
    "        dictionary to store results\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    results_dict[model_name] = {\n",
    "        \"mean_train_accuracy\": \"{:0.4f}\".format(np.mean(scores[\"train_score\"])),\n",
    "        \"mean_valid_accuracy\": \"{:0.4f}\".format(np.mean(scores[\"test_score\"])),\n",
    "        \"mean_fit_time (s)\": \"{:0.4f}\".format(np.mean(scores[\"fit_time\"])),\n",
    "        \"mean_score_time (s)\": \"{:0.4f}\".format(np.mean(scores[\"score_time\"])),\n",
    "        \"std_train_score\": \"{:0.4f}\".format(scores[\"train_score\"].std()),\n",
    "        \"std_valid_score\": \"{:0.4f}\".format(scores[\"test_score\"].std()),\n",
    "    }\n",
    "    \n",
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "agreed-synthetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/sklearn/dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time (s)</th>\n",
       "      <td>0.0114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time (s)</th>\n",
       "      <td>0.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <td>0.5003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_valid_accuracy</th>\n",
       "      <td>0.4984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_valid_score</th>\n",
       "      <td>0.0076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Dummy Classifier\n",
       "mean_fit_time (s)             0.0114\n",
       "mean_score_time (s)           0.0067\n",
       "mean_train_accuracy           0.5003\n",
       "mean_valid_accuracy           0.4984\n",
       "std_train_score               0.0017\n",
       "std_valid_score               0.0076"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set baseline model\n",
    "pipe_dclf = make_pipeline(DummyClassifier())\n",
    "scores = cross_validate(pipe_dclf, X_train, y_train, return_train_score = True)\n",
    "store_cross_val_results('Dummy Classifier', scores, results_dict)\n",
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "narrative-republic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model Decision Tree...\n",
      "Training model Decision Tree...finished\n",
      "Training model RBF SVM...\n",
      "Training model RBF SVM...finished\n",
      "Training model Naive Bayes...\n",
      "Training model Naive Bayes...finished\n",
      "Training model Logistic Regression...\n",
      "Training model Logistic Regression...finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_valid_accuracy</th>\n",
       "      <th>mean_fit_time (s)</th>\n",
       "      <th>mean_score_time (s)</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>std_valid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.5003</td>\n",
       "      <td>0.4984</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vectorizer + Decision Tree</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>24.7664</td>\n",
       "      <td>0.7601</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vectorizer + RBF SVM</th>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.8509</td>\n",
       "      <td>409.1590</td>\n",
       "      <td>77.0441</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vectorizer + Naive Bayes</th>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>3.2498</td>\n",
       "      <td>0.9361</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vectorizer + Logistic Regression</th>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.8406</td>\n",
       "      <td>19.2095</td>\n",
       "      <td>0.8026</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 mean_train_accuracy mean_valid_accuracy  \\\n",
       "Dummy Classifier                              0.5003              0.4984   \n",
       "vectorizer + Decision Tree                    1.0000              0.7090   \n",
       "vectorizer + RBF SVM                          0.9166              0.8509   \n",
       "vectorizer + Naive Bayes                      0.9091              0.7788   \n",
       "vectorizer + Logistic Regression              0.9991              0.8406   \n",
       "\n",
       "                                 mean_fit_time (s) mean_score_time (s)  \\\n",
       "Dummy Classifier                            0.0114              0.0067   \n",
       "vectorizer + Decision Tree                 24.7664              0.7601   \n",
       "vectorizer + RBF SVM                      409.1590             77.0441   \n",
       "vectorizer + Naive Bayes                    3.2498              0.9361   \n",
       "vectorizer + Logistic Regression           19.2095              0.8026   \n",
       "\n",
       "                                 std_train_score std_valid_score  \n",
       "Dummy Classifier                          0.0017          0.0076  \n",
       "vectorizer + Decision Tree                0.0000          0.0034  \n",
       "vectorizer + RBF SVM                      0.0013          0.0036  \n",
       "vectorizer + Naive Bayes                  0.0045          0.0113  \n",
       "vectorizer + Logistic Regression          0.0001          0.0119  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set other classifiers along with a pipeline consisting of a CountVectorizer object\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"RBF SVM\": SVC(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
    "}\n",
    "\n",
    "for key, model in models.items():\n",
    "    print(f\"Training model {key}...\")\n",
    "    pipe = make_pipeline(CountVectorizer(), model)\n",
    "    pipe_scores = cross_validate(pipe, X_train[\"review\"], y_train, cv=5, return_train_score=True)\n",
    "    store_cross_val_results(\"vectorizer + {}\".format(key), pipe_scores, results_dict)\n",
    "    print(f\"Training model {key}...finished\")\n",
    "    \n",
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-working",
   "metadata": {},
   "source": [
    "> From the results above we can see that `RBF SVM`, `Logistic Regression` and `Naive Bayes` are models that seem to be performing well at the task at hand, but only `RBF SVM` and `Logistic Regression` reached a mean validation score above 80. Among these three models, the one that took the longest to train by far was `RBF SVM`, while `Naive Bayes` took the shortest time. When we consider the gap between train scores and validation scores, `Decision Tree` seems to be the most overfit of all. However, even the best performing models seem to be prone to overfitting to some degree. \n",
    ">\n",
    "> Taking the time / score relation into account, I would choose `Logistic Regression` as the most appropriate model for our classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "measured-genre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                              CountVectorizer()),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression(max_iter=1000))]),\n",
       "                   n_iter=20, n_jobs=-2,\n",
       "                   param_distributions={'countvectorizer__max_features': [100,\n",
       "                                                                          2500,\n",
       "                                                                          5000,\n",
       "                                                                          10000,\n",
       "                                                                          20000,\n",
       "                                                                          25000],\n",
       "                                        'logisticregression__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter optimization using RandomSearchCV with Logistic Regression\n",
    "pipe_lr = make_pipeline(CountVectorizer(), LogisticRegression(max_iter = 1000))\n",
    "\n",
    "param_grid = {\n",
    "    \"logisticregression__C\": 10.0 ** np.arange(-3, 3),\n",
    "    \"countvectorizer__max_features\": [100, 2500, 5000, 10000, 20000, X_train.shape[0]]\n",
    "}\n",
    "random_search = RandomizedSearchCV(pipe_lr, param_distributions = param_grid, n_jobs = -2, n_iter = 20, cv = 5);\n",
    "random_search.fit(X_train['review'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "descending-russian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'logisticregression__C': 0.01, 'countvectorizer__max_features': 5000}\n",
      "Best score: 0.8662000000000001\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best score: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-relation",
   "metadata": {},
   "source": [
    "> The best scores and hyperparameter values were found at `C = 0.01` and `max_features = 5000`. With this pipeline configuration, the validation score for the `Logistic Regression` model improved a couple of points, and even exceeded that of `RBF SVM`, which was the best performing model of all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-behavior",
   "metadata": {},
   "source": [
    "### Model interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "honest-armenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.657449</td>\n",
       "      <td>0.860830</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.92170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.002771</td>\n",
       "      <td>0.847228</td>\n",
       "      <td>0.8592</td>\n",
       "      <td>0.92535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.290339</td>\n",
       "      <td>0.820774</td>\n",
       "      <td>0.8572</td>\n",
       "      <td>0.92470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.414927</td>\n",
       "      <td>1.077567</td>\n",
       "      <td>0.8622</td>\n",
       "      <td>0.92300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.100554</td>\n",
       "      <td>0.853570</td>\n",
       "      <td>0.8762</td>\n",
       "      <td>0.92100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  5.657449    0.860830      0.8696      0.92170\n",
       "1  5.002771    0.847228      0.8592      0.92535\n",
       "2  5.290339    0.820774      0.8572      0.92470\n",
       "3  5.414927    1.077567      0.8622      0.92300\n",
       "4  5.100554    0.853570      0.8762      0.92100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set pipeline and run CV on best estimator\n",
    "pipe_lr_be = make_pipeline(CountVectorizer(max_features=20000), LogisticRegression(max_iter=1000, C=0.01))\n",
    "lr_scores = cross_validate(pipe_lr_be, X_train[\"review\"], y_train, return_train_score=True)\n",
    "pd.DataFrame(lr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "common-camera",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(max_features=20000)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.01, max_iter=1000))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr_be.fit(X_train[\"review\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "familiar-given",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg words</th>\n",
       "      <th>neg weights</th>\n",
       "      <th>pos words</th>\n",
       "      <th>pos weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worst</td>\n",
       "      <td>-0.862892</td>\n",
       "      <td>job</td>\n",
       "      <td>0.257614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>waste</td>\n",
       "      <td>-0.682865</td>\n",
       "      <td>simple</td>\n",
       "      <td>0.258293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awful</td>\n",
       "      <td>-0.616819</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.262982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boring</td>\n",
       "      <td>-0.549721</td>\n",
       "      <td>fantastic</td>\n",
       "      <td>0.267735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poor</td>\n",
       "      <td>-0.466777</td>\n",
       "      <td>definitely</td>\n",
       "      <td>0.275765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bad</td>\n",
       "      <td>-0.458941</td>\n",
       "      <td>enjoyable</td>\n",
       "      <td>0.280504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>terrible</td>\n",
       "      <td>-0.438812</td>\n",
       "      <td>brilliant</td>\n",
       "      <td>0.303954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>worse</td>\n",
       "      <td>-0.437115</td>\n",
       "      <td>enjoyed</td>\n",
       "      <td>0.314259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>poorly</td>\n",
       "      <td>-0.430238</td>\n",
       "      <td>highly</td>\n",
       "      <td>0.315074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>horrible</td>\n",
       "      <td>-0.412052</td>\n",
       "      <td>fun</td>\n",
       "      <td>0.322172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dull</td>\n",
       "      <td>-0.403167</td>\n",
       "      <td>superb</td>\n",
       "      <td>0.332246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>unfortunately</td>\n",
       "      <td>-0.386392</td>\n",
       "      <td>best</td>\n",
       "      <td>0.334738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>annoying</td>\n",
       "      <td>-0.380721</td>\n",
       "      <td>today</td>\n",
       "      <td>0.344649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>disappointment</td>\n",
       "      <td>-0.373720</td>\n",
       "      <td>favorite</td>\n",
       "      <td>0.354023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ridiculous</td>\n",
       "      <td>-0.362406</td>\n",
       "      <td>loved</td>\n",
       "      <td>0.360949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>disappointing</td>\n",
       "      <td>-0.354305</td>\n",
       "      <td>amazing</td>\n",
       "      <td>0.393252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stupid</td>\n",
       "      <td>-0.352336</td>\n",
       "      <td>wonderful</td>\n",
       "      <td>0.414233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>avoid</td>\n",
       "      <td>-0.341781</td>\n",
       "      <td>great</td>\n",
       "      <td>0.426236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mess</td>\n",
       "      <td>-0.341333</td>\n",
       "      <td>perfect</td>\n",
       "      <td>0.450082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fails</td>\n",
       "      <td>-0.339981</td>\n",
       "      <td>excellent</td>\n",
       "      <td>0.576814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         neg words  neg weights   pos words  pos weights\n",
       "0            worst    -0.862892         job     0.257614\n",
       "1            waste    -0.682865      simple     0.258293\n",
       "2            awful    -0.616819   surprised     0.262982\n",
       "3           boring    -0.549721   fantastic     0.267735\n",
       "4             poor    -0.466777  definitely     0.275765\n",
       "5              bad    -0.458941   enjoyable     0.280504\n",
       "6         terrible    -0.438812   brilliant     0.303954\n",
       "7            worse    -0.437115     enjoyed     0.314259\n",
       "8           poorly    -0.430238      highly     0.315074\n",
       "9         horrible    -0.412052         fun     0.322172\n",
       "10            dull    -0.403167      superb     0.332246\n",
       "11   unfortunately    -0.386392        best     0.334738\n",
       "12        annoying    -0.380721       today     0.344649\n",
       "13  disappointment    -0.373720    favorite     0.354023\n",
       "14      ridiculous    -0.362406       loved     0.360949\n",
       "15   disappointing    -0.354305     amazing     0.393252\n",
       "16          stupid    -0.352336   wonderful     0.414233\n",
       "17           avoid    -0.341781       great     0.426236\n",
       "18            mess    -0.341333     perfect     0.450082\n",
       "19           fails    -0.339981   excellent     0.576814"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 20 words indicative of negative and positive reviews\n",
    "\n",
    "### Credit: Code adadapted from lecture notes ###\n",
    "vocab = pipe_lr_be['countvectorizer'].get_feature_names()\n",
    "weights = pipe_lr_be['logisticregression'].coef_.flatten()\n",
    "coef = np.argsort(pipe_lr_be['logisticregression'].coef_.flatten())\n",
    "\n",
    "# 20 words indicative of negative reviews\n",
    "neg_words = [vocab[idx] for idx in coef[:20]]\n",
    "\n",
    "# 20 words indicative of positive reviews\n",
    "pos_words = [vocab[idx] for idx in coef[-20:]]\n",
    "\n",
    "neg_words_weights = [(weights[idx]) for idx in coef[:20]]\n",
    "pos_words_weights = [(weights[idx]) for idx in coef[-20:]]\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"neg words\": neg_words,\n",
    "        \"neg weights\": neg_words_weights,\n",
    "        \"pos words\": pos_words,\n",
    "        \"pos weights\": pos_words_weights,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-appendix",
   "metadata": {},
   "source": [
    "> From these results, we can see that in both cases all words mapped are coherent with the type of review given to the movie. As a side note, it is intetesting to note how the negative coefficients seem to be more pronounced than the positive coefficients.\n",
    ">\n",
    "> The fact that Logistic Regression models allow access to this information is important because it provides us with tools to understand the results produced by the model. By looking at how coefficients are mapped to words we can see the impact that each feature is having on the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-degree",
   "metadata": {},
   "source": [
    "### Test score and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "latin-caution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score on test set: 0.87944\n",
      "Mean cross-validation score: 0.8648800000000001\n"
     ]
    }
   ],
   "source": [
    "# Test set score\n",
    "score = random_search.best_estimator_.score(X_test['review'], y_test)\n",
    "print(f\"Model score on test set: {score}\")\n",
    "print(f\"Mean cross-validation score: {lr_scores['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-broadway",
   "metadata": {},
   "source": [
    "> Even though the test score seems to be in line with the mean cross-validation score obtained while training the model, it should not be blindly trusted for the following reasons:\n",
    "> * The training and test sets were equally split (50%, 50%), which implies that there's room for optimization on the training process provided that we choose a different train/test split (i.e. 70-30, 80-20).\n",
    "> * The `CountVectorizer` approach of converting a collection of text documents to a vector of term/token counts might not be the most optimal approach to word encoding, as it cannot make inferences on the releationships between words. This could limit the classifier's capacity to make more accurate predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fancy-composite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive review:\n",
      "\n",
      "Probability score: 0.999999933105387\n",
      "\n",
      "Universal Studios version of \"Flipper\" (1996) is a great heartwarming film for the entire family with good values and sentimentality. It is the story of Sandy Ricks, a teenager from Chicago who reluctantly spends his vacation with his Uncle Porter Ricks in the Bahamas. This ultimately changes the teenagers life and he grows up in the process. He learns to appreciate nature and to have a respect for the environment. I grew up in the 1960's and the NBC television show \"Flipper\" was my favorite childhood show. Elijah Wood is perfectly cast as a 1990's Sandy Ricks and gives an excellent performance. As much as I liked the NBC television show and MGM theatrical feature films with Luke Halpin as Sandy in the 1960's I liked this feature the best! I feel Elijah Wood is the best Sandy Ricks. With respect to Luke Halpin I feel Elijah Wood has more of a range of acting talent and emotes more as an actor which makes his performance excellent and more believable. I think Elijah Wood is the best young actor working today in films. Director Alan Shapiro also wrote the screenplay and has done an excellent job as both writer and director of this film. Paul Hogan gives a comical and likable performance as Sandy's Uncle Porter Ricks. Mr. Hogan's performance perfectly offsets Elijah's role as Sandy. I am a big fan of underwater films. This film was beautifully shot in the Bahamas like \"Thunderball\" (1965 UA) was. The director of photography was Bill Butler A.S.C. who lensed the film \"Jaws\" in 1975. Mr. Butler is a very talented cinematographer. The underwater director of photography was Pete Romano. He did a superb job with the underwater cinematography. I enjoyed the film score by Joel McNeely. This good film score featured Crosby, Stills and Nash among other talented artists. This motion picture was shot in Panavision like \"Thunderball\" in the aspect ratio of 2.35:1 If possible try to see this film in a scope version as originally framed and visioned by Alan Shapiro and Bill Butler. Another very nice thing is that Mr. Shapiro gave the \"original\" Sandy Ricks (Luke Halpin) a small part in this remake. He portrayed Bounty Fisherman #3 in this film. This was a very kind gesture on Mr. Shapiro's part! As you can tell I am a real true fan of this film. Sadly this beautiful film was met with harsh words by the majority of movie critics. I originally saw this movie on my birthday, May 31st of 1996 in a movie theater. It meant a lot to me. I have it on numerous video versions. The VHS versions are in \"pan and scan\". The laserdisc version is \"letterboxed\" 2.35:1! I even have a VCD in 2.35:1 from Hong Kong which is \"letterboxed\". But my most prized possession is an \"original\" 16mm theatrical feature print which I will treasure for the rest of my life! Thank you Mr. Shapiro, Elijah Wood, Paul Hogan and everyone involved for making this a memorable movie for me to enjoy!<br /><br />P.S. I must add that the quality of the Universal DVD is superb! It is the best DVD as far as quality I have ever seen. The color and resolution is spectacular. The soundtrack is great. I think Universal must have used the same transfer for the DVD that they did for the laserdisc version. The 35mm scope print is \"mint\" and Alan's film really has a wonderful look to it. A great tribute to a wonderful film! The DVD's resolution is even superior to the laserdisc quality! It's just spectacular! Thank you Universal Home Video for the great quality control and transfer. Many thank's for doing a superb job on this wonderful family film. Also many thank's to you Alan for all your extreme kindness to me!!! It's a real honor to know you!!! (Review Revised/Updated June 27, 2005)\n",
      "\n",
      "Most negative review:\n",
      "\n",
      "Probability score: 0.999999996390503\n",
      "\n",
      "Plankton, or Creatures from the Abyss as I'm positive it's more commonly known as & filmed under as the title Creatures from the Abyss appears over a moving image & in the same font type as the rest of the credits, starts with five 20 something kids, Mike (Clay Rogers) his girlfriend Margaret (Sharon Twomey), sisters Julie (Ann Wolf) & Dorothy (Loren DePalm) & an annoying idiot named Bobby (Michael Bon) whom decide to all fit into a small rubber boat & head out to sea, don't ask why as I don't know. Oh & the complete idiot Bobby left the petrol behind & never thought to tell anyone so it comes as no great surprise that they end up stranded out at sea without any petrol for the motor & to make matters worse they become trapped in a thunder storm & discover a dead body floating in the water. Shortly after their luck seems to change when they come across a yacht & potential safety, in a flash everyone boards the yacht & begin to explore. First of all they find a scientific lab with various fish specimens & computer equipment, then down below they find fully furnished & luxurious cabins. They find a chemist (Deran Sarafian) who appears mad & can't talk. They eat fish from the fridge which makes Dorothy puke up green vomit, beetles & slugs. They learn that these fish are living fossil's 1000's of years old & have been contaminated by toxic waste dumped in the sea & that they fly, mutate, bite & are generally unpleasant to be around. I really can't be bothered to go on with this plot outline so I won't, here's what I think...<br /><br />This Italian production was produced & directed by Massimiliano Cerchi under the pseudonym Al Passeri (I'd hide under a different name if I made a film this bad too) & I think Plankton is quite simply one of the worst films ever, there are so many things wrong with this film it's difficult to know where to start. First the script by Richard Baumann is total crap, it makes no sense whatsoever & is so slow & dull it was torture for me to sit through. Why would five people just simply set sail for the middle of the ocean on a rubber dinghy barely big enough to fit them all in? What were they planning on doing exactly? Why do we often get point-of-view shots from these fish creatures but they seem to be totally invisible to the characters as they are never shown on screen even though they are right next to a character, & how do these fish get around the boat as there is no water for them to swim in? People's actions & reactions to things are all wrong, they constantly split up, they make bizarre decisions that simply don't make any sense in the situation they find themselves in & some of the dialogue is as awful as anything I've heard. I could go on all day about all the plot holes & ridiculous goings on but I'll run out of space if I do. The fish creatures themselves look awful, a mixture of rubbish rubber puppets & some really bad stop motion animation at the end, the scenes where they interact with the human cast also look terrible with some bad super imposition. I have heard a lot of comments saying that Plankton is gory, don't make me laugh! Forget it there is virtually no blood or gore in Plankton whatsoever, there are a couple of slimy scenes when Bobby transforms into a fish monster while having sex with Julie but it's pretty brief & he doesn't kill her, he just sort of drips slime on her, grows a couple of tentacles & a fish head comes out of his mouth. Later on Julie's vagina starts to drip some dark slime but that's it, we never get to actually see what happens to her or what the slime is. Dorothy has a fish creature come out of her back, off screen, & control her but again we never get to see what happens to her while Margaret commits suicide, a very brief shot of a plastic harpoon stuck to her forehead. Easily the grossest scene is when Dorothy pukes up that green stuff with what looks like beetles & slugs in it. That's it, only one person actually dies on screen & for the most part Plankton is quite tame & as exciting as watching paint dry & I nearly fell asleep it's so boring. I can't see how anybody can like this total crap, I just can't. The acting is awful, the dubbing is awful, the characters are awful & I hated all of them. Tecnically Plankton is predictably crap as well, with an estimated budget of only $250,000 all I can say is where did the money go? The sets are monotonous & dull with one lab & a few cabins, the special effect's are bottom of the barrel stuff including the most fake looking exploding boat ever, the cinematography is bland, the music sucks there is zero atmosphere or tension & as a whole Plankton, like it's name sake, is as low in the food chain as it could possibly be. I hate Plankton, it's awful in every single aspect of it's overlong 86 minute duration. Do yourself a favour & avoid this one at all costs unless your either a masochist or insomniac.\n"
     ]
    }
   ],
   "source": [
    "# Most representative example from negative and positive reviews\n",
    "neg_probs = pipe_lr_be.predict_proba(X_test['review'])[:, 0]\n",
    "pos_probs = pipe_lr_be.predict_proba(X_test['review'])[:, 1]\n",
    "most_neg = np.argmax(neg_probs)\n",
    "most_pos = np.argmax(pos_probs)\n",
    "print(\"Most positive review:\\n\")\n",
    "print(f\"Probability score: {pos_probs[most_pos]}\\n\")\n",
    "print(X_test.iloc[[most_pos]][\"review\"][most_pos])\n",
    "print(\"\\nMost negative review:\\n\")\n",
    "print(f\"Probability score: {neg_probs[most_neg]}\\n\")\n",
    "print(X_test.iloc[[most_neg]][\"review\"][most_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-serial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
